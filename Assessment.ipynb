{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezeAqna3-ZtY"
   },
   "source": [
    "# Project :6 Working with Structured Data: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWrIW-Bv-o23"
   },
   "source": [
    "In the realm of maritime operations, accurate detection and classification of underwater objects play a pivotal role in ensuring the safety and efficiency of various endeavours, ranging from underwater exploration to resource extraction. The Sonar dataset, comprising 208 observations, provides a comprehensive repository of sonar chirp returns, offering insights into the characteristics of submerged surfaces. With 60 input variables delineating the strength of returns at different angles, this dataset presents a formidable challenge: the binary classification of rocks and metal cylinders.By leveraging advanced predictive modelling techniques, our aim is to develop a robust solution capable of accurately discerning between these two distinct entities, thereby enhancing operational efficiency, and minimizing risks associated with underwater activities.\n",
    "\n",
    "        \n",
    "\n",
    "#### Data Set Description:\n",
    "\n",
    "The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock. Each pattern is a set of 60 numbers in the range 0.0 to 1.0. Each number represents the energy within a particular frequency band, integrated over a certain period. The label associated with each record contains the letter \"R\" if the object is a rock and \"M\" if it is a mine (metal cylinder).  \n",
    "\n",
    "**Dataset : sonar.csv**\n",
    "\n",
    "Create a first step document that lists the output of your exploratory analysis, any issues, or problems you may see with data that need follow-up, and some basic descriptive analysis that you think highlights important outcomes/findings from the data. Based on your findings, the next level of analysis will be charted out. Build a predictive base model and use hyperparameter tuning to further optimize the accuracy of the predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKNwNQ3K_Zmq"
   },
   "source": [
    "**Initial Guidelines:**\n",
    "\n",
    "1.\tEnsure to follow to Use Idâ€™s provided by UNext for naming file as conventions.\n",
    "2.\tCreate GitHub account and submit the GitHub link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Engineering aspect:  \n",
    "\n",
    "Utilize software engineering aspects while building Machine learning model using modular programming principles to organize your code into reusable functions or classes to enhance readability, maintainability, and collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA0XfSAd-hS9"
   },
   "source": [
    "### General Instructions \n",
    "\n",
    "- The cells in the Jupyter notebook can be executed any number of times for testing the solution\n",
    "- Refrain from modifying the boilerplate code as it may lead to unexpected behavior \n",
    "- The solution is to be written between the comments `# code starts here` and `# code ends here`\n",
    "- On completing all the questions, the assessment is to be submitted on moodle for evaluation\n",
    "- Before submitting the assessment, there should be `no error` while executing the notebook. If there are any error causing code, please comment it.\n",
    "- The kernel of the Jupyter notebook is to be set as `Python 3 (ipykernel)` if not set already\n",
    "- Include imports as necessary\n",
    "- For each of the task, `Note` section will provide you hints to solve the problem.\n",
    "- Do not use `PRINT` statement inside the `Except` Block. Please use `return` statement only within the except block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtP8BJM7_f2V"
   },
   "source": [
    "#### **Utilize software engineering aspects while building the  model using modular programming principles to organize your code into reusable functions or classes to enhance readability, maintainability, and collaboration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lvqgkFGS1XTE"
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi-xguRr1wqP"
   },
   "source": [
    "### Task 1: Load the dataset and perform preliminary EDA with key observations and insights- (weightage - 20 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wt_fkG4Z1-Se"
   },
   "source": [
    "#### T1.1: Load the sonar dataset using try and except blocks.          (weightage - 2 marks) (AE)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- The `read_csv` method in Pandas allows you to read csv files and convert them into a DataFrame, which is a two-dimensional tabular data structure in Pandas.\n",
    "- Do not use `PRINT` statement inside the `Except` Block. Please use `return` statement only within the except block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-hUjOO4D4wUQ"
   },
   "outputs": [],
   "source": [
    "def load_the_dataset():\n",
    "    try:\n",
    "    # code starts here\n",
    "        df_sonar = pd.read_csv('sonar1.csv')\n",
    "    # code ends here\n",
    "        return df_sonar\n",
    "    except:\n",
    "        return \"File not found. Please check the file path.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_jk7pNE2Ux2",
    "outputId": "00f6e5b0-3daf-44df-eab4-d74702d6fa71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  \\\n",
      "0             0      0.0200      0.0371      0.0428      0.0207      0.0954   \n",
      "1             1      0.0453      0.0523      0.0843      0.0689      0.1183   \n",
      "2             2      0.0262      0.0582      0.1099      0.1083      0.0974   \n",
      "3             3      0.0100      0.0171      0.0623      0.0205      0.0205   \n",
      "4             4      0.0762      0.0666      0.0481      0.0394      0.0590   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "203         203      0.0187      0.0346      0.0168      0.0177      0.0393   \n",
      "204         204      0.0323      0.0101      0.0298      0.0564      0.0760   \n",
      "205         205      0.0522      0.0437      0.0180      0.0292      0.0351   \n",
      "206         206      0.0303      0.0353      0.0490      0.0608      0.0167   \n",
      "207         207      0.0260      0.0363      0.0136      0.0272      0.0214   \n",
      "\n",
      "     Attribute6  Attribute7  Attribute8  Attribute9  ...  Attribute52  \\\n",
      "0        0.0986      0.1539      0.1601      0.3109  ...       0.0027   \n",
      "1        0.2583      0.2156      0.3481      0.3337  ...       0.0084   \n",
      "2        0.2280      0.2431      0.3771      0.5598  ...       0.0232   \n",
      "3        0.0368      0.1098      0.1276      0.0598  ...       0.0121   \n",
      "4        0.0649      0.1209      0.2467      0.3564  ...       0.0031   \n",
      "..          ...         ...         ...         ...  ...          ...   \n",
      "203      0.1630      0.2028      0.1694      0.2328  ...       0.0116   \n",
      "204      0.0958      0.0990      0.1018      0.1030  ...       0.0061   \n",
      "205      0.1171      0.1257      0.1178      0.1258  ...       0.0160   \n",
      "206      0.1354      0.1465      0.1123      0.1945  ...       0.0086   \n",
      "207      0.0338      0.0655      0.1400      0.1843  ...       0.0146   \n",
      "\n",
      "     Attribute53  Attribute54  Attribute55  Attribute56  Attribute57  \\\n",
      "0         0.0065       0.0159       0.0072       0.0167       0.0180   \n",
      "1         0.0089       0.0048       0.0094       0.0191       0.0140   \n",
      "2         0.0166       0.0095       0.0180       0.0244       0.0316   \n",
      "3         0.0036       0.0150       0.0085       0.0073       0.0050   \n",
      "4         0.0054       0.0105       0.0110       0.0015       0.0072   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "203       0.0098       0.0199       0.0033       0.0101       0.0065   \n",
      "204       0.0093       0.0135       0.0063       0.0063       0.0034   \n",
      "205       0.0029       0.0051       0.0062       0.0089       0.0140   \n",
      "206       0.0046       0.0126       0.0036       0.0035       0.0034   \n",
      "207       0.0129       0.0047       0.0039       0.0061       0.0040   \n",
      "\n",
      "     Attribute58  Attribute59  Attribute60  class  \n",
      "0         0.0084       0.0090       0.0032      R  \n",
      "1         0.0049       0.0052       0.0044      R  \n",
      "2         0.0164       0.0095       0.0078      R  \n",
      "3         0.0044       0.0040       0.0117      R  \n",
      "4         0.0048       0.0107       0.0094      R  \n",
      "..           ...          ...          ...    ...  \n",
      "203       0.0115       0.0193       0.0157      M  \n",
      "204       0.0032       0.0062       0.0067      M  \n",
      "205       0.0138       0.0077       0.0031      M  \n",
      "206       0.0079       0.0036       0.0048      M  \n",
      "207       0.0036       0.0061       0.0115      M  \n",
      "\n",
      "[208 rows x 62 columns]\n"
     ]
    }
   ],
   "source": [
    "# store the result of the dataset\n",
    "df_sonar =load_the_dataset()\n",
    "print(df_sonar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOhYH2Ns2epX"
   },
   "source": [
    "#### T1.2: What is the distribution of target variable? (Mention in percentage)(weightage - 2 marks)  (AE)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:\n",
    "\n",
    "* Design a method `target_class` to analyze the distribution of a target variable (\"class\") within a DataFrame (df). \n",
    "* Count the occurrences of each unique value in the 'class' column of the DataFrame df using the `value_counts` method\n",
    "* Normalizes the counts to obtain proportions instead of counts.\n",
    "* Scale the proportions to percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PxSnZoUG2gsA"
   },
   "outputs": [],
   "source": [
    "def target_class(df):\n",
    "    #code starts here\n",
    "    try:\n",
    "        target_dist = df['class'].value_counts(normalize=True) * 100\n",
    "    #code ends\n",
    "        return target_dist\n",
    "    except KeyError:\n",
    "        return \"Target variable 'class' not found in the DataFrame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOve-YPr3SY3",
    "outputId": "d24fdbcb-b07d-49dc-b355-7c035cec0db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M    53.365385\n",
      "R    46.634615\n",
      "Name: class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# store the result\n",
    "target_distribution = target_class(df_sonar)\n",
    "print(target_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM6CxQDW4j3b"
   },
   "source": [
    "#### T1.3: Remove the unnecessary column. (weightage - 2 marks)               (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "* Unnamed: 0 is the unecessary column.\n",
    "* Use `drop` method of the dataframe to drop the unnecessary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LGgGQLE1f80f"
   },
   "outputs": [],
   "source": [
    "def unecessary_col(df):\n",
    "    #code starts here\n",
    "    df_updated = df.drop('Unnamed: 0', axis=1, errors='ignore')\n",
    "    #code ends here\n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5U2e7Nk4wHt",
    "outputId": "8577ec29-9103-42d6-a7c9-4dab79887e3a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  Attribute6  \\\n",
      "0        0.0200      0.0371      0.0428      0.0207      0.0954      0.0986   \n",
      "1        0.0453      0.0523      0.0843      0.0689      0.1183      0.2583   \n",
      "2        0.0262      0.0582      0.1099      0.1083      0.0974      0.2280   \n",
      "3        0.0100      0.0171      0.0623      0.0205      0.0205      0.0368   \n",
      "4        0.0762      0.0666      0.0481      0.0394      0.0590      0.0649   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "203      0.0187      0.0346      0.0168      0.0177      0.0393      0.1630   \n",
      "204      0.0323      0.0101      0.0298      0.0564      0.0760      0.0958   \n",
      "205      0.0522      0.0437      0.0180      0.0292      0.0351      0.1171   \n",
      "206      0.0303      0.0353      0.0490      0.0608      0.0167      0.1354   \n",
      "207      0.0260      0.0363      0.0136      0.0272      0.0214      0.0338   \n",
      "\n",
      "     Attribute7  Attribute8  Attribute9  Attribute10  ...  Attribute52  \\\n",
      "0        0.1539      0.1601      0.3109       0.2111  ...       0.0027   \n",
      "1        0.2156      0.3481      0.3337       0.2872  ...       0.0084   \n",
      "2        0.2431      0.3771      0.5598       0.6194  ...       0.0232   \n",
      "3        0.1098      0.1276      0.0598       0.1264  ...       0.0121   \n",
      "4        0.1209      0.2467      0.3564       0.4459  ...       0.0031   \n",
      "..          ...         ...         ...          ...  ...          ...   \n",
      "203      0.2028      0.1694      0.2328       0.2684  ...       0.0116   \n",
      "204      0.0990      0.1018      0.1030       0.2154  ...       0.0061   \n",
      "205      0.1257      0.1178      0.1258       0.2529  ...       0.0160   \n",
      "206      0.1465      0.1123      0.1945       0.2354  ...       0.0086   \n",
      "207      0.0655      0.1400      0.1843       0.2354  ...       0.0146   \n",
      "\n",
      "     Attribute53  Attribute54  Attribute55  Attribute56  Attribute57  \\\n",
      "0         0.0065       0.0159       0.0072       0.0167       0.0180   \n",
      "1         0.0089       0.0048       0.0094       0.0191       0.0140   \n",
      "2         0.0166       0.0095       0.0180       0.0244       0.0316   \n",
      "3         0.0036       0.0150       0.0085       0.0073       0.0050   \n",
      "4         0.0054       0.0105       0.0110       0.0015       0.0072   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "203       0.0098       0.0199       0.0033       0.0101       0.0065   \n",
      "204       0.0093       0.0135       0.0063       0.0063       0.0034   \n",
      "205       0.0029       0.0051       0.0062       0.0089       0.0140   \n",
      "206       0.0046       0.0126       0.0036       0.0035       0.0034   \n",
      "207       0.0129       0.0047       0.0039       0.0061       0.0040   \n",
      "\n",
      "     Attribute58  Attribute59  Attribute60  class  \n",
      "0         0.0084       0.0090       0.0032      R  \n",
      "1         0.0049       0.0052       0.0044      R  \n",
      "2         0.0164       0.0095       0.0078      R  \n",
      "3         0.0044       0.0040       0.0117      R  \n",
      "4         0.0048       0.0107       0.0094      R  \n",
      "..           ...          ...          ...    ...  \n",
      "203       0.0115       0.0193       0.0157      M  \n",
      "204       0.0032       0.0062       0.0067      M  \n",
      "205       0.0138       0.0077       0.0031      M  \n",
      "206       0.0079       0.0036       0.0048      M  \n",
      "207       0.0036       0.0061       0.0115      M  \n",
      "\n",
      "[208 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "#Store the result into a new dataframe\n",
    "df_sonar_updated = unecessary_col(df_sonar)\n",
    "print(df_sonar_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlWK2YOM5cnK"
   },
   "source": [
    "#### T1.4: Check missing values in the data in terms of percentage and do missing value treatment.  (weightage - 2 marks)       (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "- Find the percentage of missing values in the data by dividing the total number of missing values by the total number of rows and multiplying by 100, you will get the percentage of missing values for each column. \n",
    "- Use `isnull().sum()` to calculate the total number of missing values in each column and `shape[0]` to get the total number of rows in the DataFrame.\n",
    "- Do not use `PRINT` statement inside the `Except` Block. Please use `return` statement only within the except block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PvO0lzXqfa4U"
   },
   "outputs": [],
   "source": [
    "def missing_value_check(df):\n",
    "    #Code starts here\n",
    "    try:\n",
    "        # Calculate percentage of missing values for each column\n",
    "        missing_percentage = (df.isnull().sum() / df.shape[0]) * 100\n",
    "        \n",
    "        # Print or return the missing percentage for each column\n",
    "        return missing_percentage\n",
    "    except:\n",
    "        return \"Error: Unable to check missing values.\"\n",
    "    # Code ends here   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wWgPWS649LK",
    "outputId": "1da9ab48-251b-40b5-f35f-74651115e55a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute1     0.0\n",
      "Attribute2     0.0\n",
      "Attribute3     0.0\n",
      "Attribute4     0.0\n",
      "Attribute5     0.0\n",
      "              ... \n",
      "Attribute57    0.0\n",
      "Attribute58    0.0\n",
      "Attribute59    0.0\n",
      "Attribute60    0.0\n",
      "class          0.0\n",
      "Length: 61, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(missing_value_check(df_sonar_updated))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "* For treating the missing value first define the list of columns containing the names of the columns with missing values which will be treated. \n",
    "* Iterating over each column name in the columns list fill the missing values in the dataset for that column with the median value of that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "u0ohbEqvhHwD"
   },
   "outputs": [],
   "source": [
    "# Missing value treatment\n",
    "def missing_value_treatment(df):\n",
    "    # Code starts here\n",
    "    try:\n",
    "        columns_with_missing = df.columns[df.isnull().any()].tolist()\n",
    "        \n",
    "        for col in columns_with_missing:\n",
    "            median_value = df[col].median()\n",
    "            df[col].fillna(median_value, inplace=True)\n",
    "    # Code ends here\n",
    "        return df  \n",
    "    except:\n",
    "        return \"Error: Unable to perform missing value treatment.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dN056jXQ6Nh2",
    "outputId": "937bdf8b-c866-47a7-caa0-3b54923675d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute1     0\n",
      "Attribute2     0\n",
      "Attribute3     0\n",
      "Attribute4     0\n",
      "Attribute5     0\n",
      "              ..\n",
      "Attribute57    0\n",
      "Attribute58    0\n",
      "Attribute59    0\n",
      "Attribute60    0\n",
      "class          0\n",
      "Length: 61, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check if missing values are treated\n",
    "df_sonar_updated = missing_value_treatment(df_sonar_updated)\n",
    "print(df_sonar_updated.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yOdDzyS7Aiq"
   },
   "source": [
    "#### T1.5: Visualize the correlation matrix using a heatmap for first 4 input variables. What is the Pearson correlation coefficient between the Attribute1 and Attribute 2? (Bivariate analysis) (weightage - 3 marks)               (AE and ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "* Define a method called `correlation_matrix` to calculate the Pearson correlation coefficient between two specific columns   ('Attribute 1' and 'Attribute 2') in a DataFrame (df).\n",
    "* Use the `iloc` method to select only the columns corresponding to 'Attribute 1' and 'Attribute 2' from the DataFrame df.\n",
    "* Calculate the Pearson correlation coefficient using the corr() method on the selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "c1jWoKmt55Hi"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pearson correlation coefficient for Attribute 1 and Attribute 2\n",
    "def correlation_matrix(df):\n",
    "    # Code starts here\n",
    "    try:\n",
    "        input_variables = df.iloc[:, :2]\n",
    "        corr_matrix = input_variables.corr()\n",
    "        \n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", annot_kws={\"size\": 10})\n",
    "        plt.title('Correlation Matrix Heatmap')\n",
    "        plt.show()\n",
    "        \n",
    "        correlation = input_variables['Attribute 1'].corr(input_variables['Attribute 2'])\n",
    "        return correlation\n",
    "    except KeyError:\n",
    "        return \"Error: One or more specified columns not found in the DataFrame.\"\n",
    "    # Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J9taquCL78Wm",
    "outputId": "467e068e-bc43-47dc-a73a-1ad8951a24ef",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: One or more specified columns not found in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "Correlation_Attribute_1_2 = correlation_matrix(df_sonar_updated)\n",
    "print(Correlation_Attribute_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "* Generate a heatmap visualization of the correlation matrix for the specified subset of columns in the DataFrame \n",
    "* Select the first four columns (indexed 0, 1, 2, and 3) of the DataFrame using integer-based indexing. \n",
    "* Using seaborn `heatmap` method, generate a heatmap plot of the correlation matrix.\n",
    "* Using `annot` parameter, display correlation coefficients inside each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "rpkyDMBi8GWQ",
    "outputId": "4481533f-801f-4c4b-cf36-29e4aaebcc2b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize using Heatmap\n",
    "subset_columns = df_sonar_updated.iloc[:, :4]\n",
    "corr_matrix = subset_columns.corr()\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", annot_kws={\"size\": 10})\n",
    "plt.title('Correlation Matrix Heatmap for First Four Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEg2xZQX8cF4"
   },
   "source": [
    "#### T1.6. Perform PCA (Principal Component Analysis) on the input variables. Display the cumulative variance array along with the number of principal components required to capture 90% of information. How many principal components are required to capture 90% of the information?  (AE) 2 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "* Define a method called `pca_inputs` to perform Principal Component Analysis (PCA) on the input DataFrame (df) for the first 60 columns.\n",
    "* Create a copy of the first 60 columns of the DataFrame df.* and assign it to a new DataFrame `df2`.\n",
    "* Initialize a StandardScaler object (sc) to standardize the data.\n",
    "* Standardize the data in `df2` using sc.fit_transform(df2), and store the standardized data in a new DataFrame dfsc.\n",
    "* Convert dfsc back to a DataFrame with column names from df2 using pd.DataFrame(dfsc, columns=df2.columns)\n",
    "* Initialize a PCA object (finalpca) for performing PCA.\n",
    "* Perform PCA on the standardized data dfsc using `finalpca.fit_transform(dfsc)` and store the transformed data in finaldf.\n",
    "* Obtain the explained variance ratio of each principal component using finalpca.explained_variance_ratio_\n",
    "* Calculate the number of principal components needed to explain at least 90% of the variance by iterating through the cumulative sum of explained variances (np.cumsum(variation))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2XKv6Xg18xrG"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def pca_inputs(df):\n",
    "    try:\n",
    "        # Selecting the first 60 columns for PCA\n",
    "        df2 = df.iloc[:, :60].copy()\n",
    "        \n",
    "        # Standardizing the data\n",
    "        sc = StandardScaler()\n",
    "        dfsc = sc.fit_transform(df2)\n",
    "        dfsc = pd.DataFrame(dfsc, columns=df2.columns)\n",
    "        \n",
    "        # Performing PCA\n",
    "        finalpca = PCA()\n",
    "        finaldf = finalpca.fit_transform(dfsc)\n",
    "        \n",
    "        # Explained variance ratio of each principal component\n",
    "        variance = finalpca.explained_variance_ratio_\n",
    "        \n",
    "        # Calculating cumulative variance\n",
    "        cumulative_variance = np.cumsum(variance)\n",
    "        \n",
    "        # Finding the number of principal components that capture 90% of information\n",
    "        for i, cum_var in enumerate(cumulative_variance):\n",
    "            if cum_var >= 0.90:\n",
    "                count = i + 1 \n",
    "                break\n",
    "        \n",
    "        return cumulative_variance, count\n",
    "    \n",
    "    except Exception as e:\n",
    "        return \"Error: Unable to perform PCA.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSvXGdgF8xts",
    "outputId": "7bc0a5dc-049f-4a6e-d068-c6d484fe486c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative variance :[0.20372013 0.39240256 0.47791603 0.53442693 0.58446497 0.62513389\n",
      " 0.6576164  0.68827564 0.71340088 0.73707394 0.75846917 0.77747927\n",
      " 0.79495787 0.81021968 0.82454013 0.83809472 0.85041426 0.86212083\n",
      " 0.87247607 0.88235948 0.89193517 0.90088052 0.90940274 0.91713441\n",
      " 0.92442858 0.93156896 0.93782163 0.94335663 0.94860861 0.95381911\n",
      " 0.95854518 0.96299091 0.9666294  0.97008747 0.9734147  0.97642876\n",
      " 0.97930819 0.98181733 0.98407149 0.98607485 0.98785671 0.98944904\n",
      " 0.99080305 0.99204566 0.99310904 0.99408868 0.99503067 0.9957696\n",
      " 0.99637763 0.9969047  0.99740263 0.99787272 0.99827773 0.99866079\n",
      " 0.9989825  0.99925705 0.9995042  0.99969824 0.99988887 1.        ]\n",
      "Number of principal components that capture 90% of information :22\n"
     ]
    }
   ],
   "source": [
    "# Print the cumulative variance and specify the number of principal components that capture 90% of information\n",
    "cumulative_variance,count = pca_inputs(df_sonar_updated)\n",
    "print(f'Cumulative variance :{cumulative_variance}')\n",
    "print(f'Number of principal components that capture 90% of information :{count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcLA99Hs_gHL"
   },
   "source": [
    "#### T1.7: Data Transformation:  Apply normalization technique (standard scalar). (weightage - 3 marks)        (AE)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "* Define a method called `normalize` to normalize the first 60 columns of a DataFrame (df).\n",
    "* Use the `iloc` method to select the first 60 columns of the DataFrame df, and apply the StandardScaler to standardize these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bTD4LjVJ8xwN"
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    try:\n",
    "        df_subset = df.iloc[:, :60].copy()\n",
    "        \n",
    "        # Initialize StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Fit and transform the data\n",
    "        df_normalized = scaler.fit_transform(df_subset)\n",
    "        \n",
    "        # Convert numpy array back to DataFrame with original column names\n",
    "        df_normalized = pd.DataFrame(df_normalized, columns=df_subset.columns)\n",
    "        \n",
    "        return df_normalized\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RopgyCSU8xyv",
    "outputId": "bd6b952a-1b6a-42db-8dd1-d70160f6440c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  Attribute6  \\\n",
      "0     -0.399551   -0.040648   -0.026926   -0.715105    0.364456   -0.101253   \n",
      "1      0.703538    0.421630    1.055618    0.323330    0.777676    2.607217   \n",
      "2     -0.129229    0.601067    1.723404    1.172176    0.400545    2.093337   \n",
      "3     -0.835555   -0.648910    0.481740   -0.719414   -0.987079   -1.149364   \n",
      "4      2.050790    0.856537    0.111327   -0.312227   -0.292365   -0.672796   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "203   -0.456232   -0.116681   -0.705146   -0.779738   -0.647842    0.990954   \n",
      "204    0.136733   -0.861801   -0.366036    0.054026    0.014392   -0.148740   \n",
      "205    1.004381    0.160078   -0.673843   -0.531979   -0.723629    0.212502   \n",
      "206    0.049533   -0.095392    0.134804    0.148821   -1.055648    0.522865   \n",
      "207   -0.137949   -0.064979   -0.788619   -0.575067   -0.970839   -1.200244   \n",
      "\n",
      "     Attribute7  Attribute8  Attribute9  Attribute10  ...  Attribute51  \\\n",
      "0      0.682505    0.297843    1.125272     0.021186  ...     0.595283   \n",
      "1      1.795719    2.510982    1.318325     0.588706  ...    -0.297902   \n",
      "2      2.291885    2.852370    3.232767     3.066105  ...    -1.065875   \n",
      "3     -0.113164   -0.084747   -1.000852    -0.610469  ...     0.670411   \n",
      "4      0.087107    1.317299    1.510531     1.772220  ...    -0.039129   \n",
      "..          ...         ...         ...          ...  ...          ...   \n",
      "203    1.564777    0.407323    0.463980     0.448504  ...     0.353205   \n",
      "204   -0.308022   -0.388465   -0.635067     0.053253  ...    -0.915619   \n",
      "205    0.173710   -0.200113   -0.442014     0.332912  ...    -0.047477   \n",
      "206    0.548991   -0.264859    0.139685     0.202404  ...    -0.990747   \n",
      "207   -0.912441    0.061226    0.053319     0.202404  ...     0.169559   \n",
      "\n",
      "     Attribute52  Attribute53  Attribute54  Attribute55  Attribute56  \\\n",
      "0      -1.115432    -0.597604     0.680897    -0.295646     1.481635   \n",
      "1      -0.522349    -0.256857    -0.843151     0.015503     1.901046   \n",
      "2       1.017585     0.836373    -0.197833     1.231812     2.827246   \n",
      "3      -0.137365    -1.009341     0.557326    -0.111785    -0.161060   \n",
      "4      -1.073812    -0.753780    -0.060532     0.241793    -1.174638   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "203    -0.189390    -0.129077     1.230104    -0.847228     0.328253   \n",
      "204    -0.761663    -0.200066     0.351373    -0.422934    -0.335815   \n",
      "205     0.268428    -1.108725    -0.801960    -0.437077     0.118548   \n",
      "206    -0.501539    -0.867363     0.227802    -0.804798    -0.825128   \n",
      "207     0.122759     0.311055    -0.856881    -0.762369    -0.370766   \n",
      "\n",
      "     Attribute57  Attribute58  Attribute59  Attribute60  \n",
      "0       1.763784     0.069870     0.171678    -0.658947  \n",
      "1       1.070732    -0.472406    -0.444554    -0.419852  \n",
      "2       4.120162     1.309360     0.252761     0.257582  \n",
      "3      -0.488635    -0.549875    -0.639154     1.034640  \n",
      "4      -0.107456    -0.487900     0.447361     0.576375  \n",
      "..           ...          ...          ...          ...  \n",
      "203    -0.228741     0.550172     1.841992     1.831621  \n",
      "204    -0.765856    -0.735798    -0.282388     0.038412  \n",
      "205     1.070732     0.906526    -0.039138    -0.678871  \n",
      "206    -0.765856    -0.007598    -0.704020    -0.340154  \n",
      "207    -0.661898    -0.673823    -0.298604     0.994790  \n",
      "\n",
      "[208 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "# Save the standardized data\n",
    "df_normalized = normalize(df_sonar_updated)\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGH-2yFqAMoH"
   },
   "source": [
    "#### T1.8: Handling categorical features: Apply label encoding technique to convert categorical variable into numerical. (weightage - 2 marks) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "* Define a method called `label_encode` to perform label encoding on a categorical column ('class') in a DataFrame (df).\n",
    "* Initialize a LabelEncoder object (encoder) for encoding categorical labels.\n",
    "* Use encoder.fit_transform(df[['class']]) to fit and transform the 'class' column into encoded labels. Wrap the result in a DataFrame using pd.DataFrame(...) and assign it to encoded_y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7GGwrKUI8x2F"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def label_encode(df):\n",
    "    # Code starts here\n",
    "    try:\n",
    "        # Initialize LabelEncoder\n",
    "        encoder = LabelEncoder()\n",
    "        \n",
    "        # Fit and transform the 'class' column into encoded labels\n",
    "        encoded_y = encoder.fit_transform(df['class'])\n",
    "        \n",
    "        # Convert the result to a DataFrame\n",
    "        encoded_y = pd.DataFrame(encoded_y, columns=['encoded_class'])\n",
    "        \n",
    "        return encoded_y\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15bzftDICe1q",
    "outputId": "7444ed20-0a70-441c-9636-c9638c486ee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     encoded_class\n",
      "0                1\n",
      "1                1\n",
      "2                1\n",
      "3                1\n",
      "4                1\n",
      "..             ...\n",
      "203              0\n",
      "204              0\n",
      "205              0\n",
      "206              0\n",
      "207              0\n",
      "\n",
      "[208 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply label encoding to class variable\n",
    "encoded_class = label_encode(df_sonar_updated)\n",
    "print(encoded_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqk4Qh1NDN_P"
   },
   "source": [
    "#### T1.9: Save the cleaned dataset (.xlsx file) by setting the index=False in your GitHub repository for model building process. (This task is for maintaining the version control of datasets)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refer to the Github document from Lumen to create the repository and steps to commit \n",
    "#### Add your Github repository link below "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "* Concatenate two DataFrames `df_normalized` and `encoded_class` horizontally along the `columns` using the `concat` method\n",
    "* Using `to_excel` method and setting `index` parameter to `False` save the final dataset in __EXCEL [.xlsx]__ format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BszPzlACDPwe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully to cleaned_dataset.xlsx\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.concat([df_normalized, encoded_class], axis=1)\n",
    "file_path = 'cleaned_dataset.xlsx'\n",
    "try:\n",
    "    final_df.to_excel(file_path, index=False)\n",
    "    print(f\"Dataset saved successfully to {file_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8NPSwxMaGYu1"
   },
   "outputs": [],
   "source": [
    "# save it in github repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Github repository link\n",
    "LaTeX:  ð›¼2\n",
    "https://github.com/Smitam16/DL_Usecase6_Cleaned-dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNVfVICBDknW"
   },
   "source": [
    "### Task 2: Build a Neural Network Predictive Model with Grid Search (weightage - 30 marks)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-neHX2NrEhLt"
   },
   "source": [
    "#### T2.1: Load the cleaned dataset and divide it into predictor and target values (X & y) (weightage â€“ 5 marks) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "\n",
    "* Define a method called `load_the_cleaned_dataset` to load a cleaned dataset from an Excel file named 'df_final.xlsx'.\n",
    "* Use the `pd.read_excel` function to read the Excel file and store the data in a DataFrame called cleaned_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2vcS5frK6HBm"
   },
   "outputs": [],
   "source": [
    "# load the cleaned data\n",
    "def load_the_cleaned_dataset():\n",
    "        try:\n",
    "            # Code starts here\n",
    "            cleaned_df = pd.read_excel('cleaned_dataset.xlsx')\n",
    "            # Code ends here\n",
    "            return cleaned_df\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  Attribute6  \\\n",
      "0     -0.399551   -0.040648   -0.026926   -0.715105    0.364456   -0.101253   \n",
      "1      0.703538    0.421630    1.055618    0.323330    0.777676    2.607217   \n",
      "2     -0.129229    0.601067    1.723404    1.172176    0.400545    2.093337   \n",
      "3     -0.835555   -0.648910    0.481740   -0.719414   -0.987079   -1.149364   \n",
      "4      2.050790    0.856537    0.111327   -0.312227   -0.292365   -0.672796   \n",
      "..          ...         ...         ...         ...         ...         ...   \n",
      "203   -0.456232   -0.116681   -0.705146   -0.779738   -0.647842    0.990954   \n",
      "204    0.136733   -0.861801   -0.366036    0.054026    0.014392   -0.148740   \n",
      "205    1.004381    0.160078   -0.673843   -0.531979   -0.723629    0.212502   \n",
      "206    0.049533   -0.095392    0.134804    0.148821   -1.055648    0.522865   \n",
      "207   -0.137949   -0.064979   -0.788619   -0.575067   -0.970839   -1.200244   \n",
      "\n",
      "     Attribute7  Attribute8  Attribute9  Attribute10  ...  Attribute52  \\\n",
      "0      0.682505    0.297843    1.125272     0.021186  ...    -1.115432   \n",
      "1      1.795719    2.510982    1.318325     0.588706  ...    -0.522349   \n",
      "2      2.291885    2.852370    3.232767     3.066105  ...     1.017585   \n",
      "3     -0.113164   -0.084747   -1.000852    -0.610469  ...    -0.137365   \n",
      "4      0.087107    1.317299    1.510531     1.772220  ...    -1.073812   \n",
      "..          ...         ...         ...          ...  ...          ...   \n",
      "203    1.564777    0.407323    0.463980     0.448504  ...    -0.189390   \n",
      "204   -0.308022   -0.388465   -0.635067     0.053253  ...    -0.761663   \n",
      "205    0.173710   -0.200113   -0.442014     0.332912  ...     0.268428   \n",
      "206    0.548991   -0.264859    0.139685     0.202404  ...    -0.501539   \n",
      "207   -0.912441    0.061226    0.053319     0.202404  ...     0.122759   \n",
      "\n",
      "     Attribute53  Attribute54  Attribute55  Attribute56  Attribute57  \\\n",
      "0      -0.597604     0.680897    -0.295646     1.481635     1.763784   \n",
      "1      -0.256857    -0.843151     0.015503     1.901046     1.070732   \n",
      "2       0.836373    -0.197833     1.231812     2.827246     4.120162   \n",
      "3      -1.009341     0.557326    -0.111785    -0.161060    -0.488635   \n",
      "4      -0.753780    -0.060532     0.241793    -1.174638    -0.107456   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "203    -0.129077     1.230104    -0.847228     0.328253    -0.228741   \n",
      "204    -0.200066     0.351373    -0.422934    -0.335815    -0.765856   \n",
      "205    -1.108725    -0.801960    -0.437077     0.118548     1.070732   \n",
      "206    -0.867363     0.227802    -0.804798    -0.825128    -0.765856   \n",
      "207     0.311055    -0.856881    -0.762369    -0.370766    -0.661898   \n",
      "\n",
      "     Attribute58  Attribute59  Attribute60  encoded_class  \n",
      "0       0.069870     0.171678    -0.658947              1  \n",
      "1      -0.472406    -0.444554    -0.419852              1  \n",
      "2       1.309360     0.252761     0.257582              1  \n",
      "3      -0.549875    -0.639154     1.034640              1  \n",
      "4      -0.487900     0.447361     0.576375              1  \n",
      "..           ...          ...          ...            ...  \n",
      "203     0.550172     1.841992     1.831621              0  \n",
      "204    -0.735798    -0.282388     0.038412              0  \n",
      "205     0.906526    -0.039138    -0.678871              0  \n",
      "206    -0.007598    -0.704020    -0.340154              0  \n",
      "207    -0.673823    -0.298604     0.994790              0  \n",
      "\n",
      "[208 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "cleaned_df=load_the_cleaned_dataset()\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCxduowDG4e6"
   },
   "source": [
    "- Separate independent features and target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "\n",
    "* Define a method called `separate_data_and_target` to separate the independent features and the target variable from a DataFrame (df).\n",
    "* Use the `drop` method on the DataFrame df to create a new DataFrame `X` containing only the independent features. Drop the `class` column along the columns axis (axis=1).\n",
    "* Create a Series `y` containing the target variable by selecting only the `class` column from the original DataFrame df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EE27qRiE7En_"
   },
   "outputs": [],
   "source": [
    "# Separate independent features and target variable\n",
    "def separate_data_and_target(cleaned_df):\n",
    "    # Code starts here\n",
    "    try:\n",
    "        X= cleaned_df.drop('encoded_class', axis = 'columns' )\n",
    "        y= cleaned_df['encoded_class']\n",
    "        # Code ends here\n",
    "        return X,y\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zipPZZTzG_Xh",
    "outputId": "6766efcc-9527-4b32-b3a2-29d42ba80ca8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 60)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dependent : X, independent : y\n",
    "X, y = separate_data_and_target(cleaned_df)\n",
    "X.shape\n",
    "# y.shape\n",
    "# print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BA_sF11OHI7R",
    "outputId": "f3a0ab90-0bc4-4158-bea9-2572f3bb98a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: encoded_class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmBLM3NWF3KM"
   },
   "source": [
    "#### T2.2: Split the dataset into train and test in the ratio of 80:20. (weightage â€“ 5 marks) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Define a method called `split_into_train_and_test_normalize_features` to split the features (X) and target variable (y) into training and testing sets, and normalize the features.\n",
    "* Use the `train_test_split` function to split the features (X) and target variable (y) into training and testing sets. Specify the test size as 20% (test_size = .2) and set a random state for reproducibility (random_state=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "4JsY8CR9BbsT"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_into_train_and_test_normalize_features(X,y):\n",
    "    # Code starts here\n",
    "    # Splitting dataset to train and test sets 80% train and 20% test\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=5)\n",
    "        # Code ends here\n",
    "        return X_train, X_test,y_train,y_test\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ieJZPscjHFj9"
   },
   "outputs": [],
   "source": [
    "# split into training and testing\n",
    "X_train, X_test,y_train,y_test=split_into_train_and_test_normalize_features(X,y)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03vqMsbKGfHp"
   },
   "source": [
    "#### Build NN model on training data.Perform hyperparameter tuning using Grid Search. What are the epochs, batch size, and optimizers were selected using grid search?\n",
    "\n",
    "**Model_versioning**\n",
    "\n",
    "Save the model as â€˜NN_modelâ€™ to a version control system GitHub using git commands for collaboration, tracking changes, and ensuring transparency in model development. --- (weightage 20 marks ) (ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "\n",
    "* Define a method called `create_baseline` to create a baseline neural network model.\n",
    "* Inside the method:\n",
    "    * Create a Sequential model using Sequential() from Keras.\n",
    "    * Add a Dense layer with 60 units (assuming 60 input features), specify input_dim=60, use 'normal' kernel initializer, and set activation='relu'.\n",
    "    * Add another Dense layer with 1 unit for binary classification, use 'normal' kernel initializer, and set activation='sigmoid'.\n",
    "    * Compile the model using model.compile() with 'binary_crossentropy' as the loss function, 'adam' optimizer, and include 'accuracy' as a metric.\n",
    "* Create Pipeline and Grid Search:\n",
    "    * Create a pipeline using Pipeline from sklearn.pipeline.\n",
    "    * Include the KerasClassifier within the pipeline, specifying the build function as create_baseline and set verbose=0.\n",
    "    * Define the grid search parameters in a dictionary param_grid, such as different batch sizes and epochs.\n",
    "* Perform Grid Search:\n",
    "    * Initialize a StratifiedKFold with the desired number of splits (e.g., StratifiedKFold(n_splits=10, shuffle=True)).\n",
    "    * Use GridSearchCV with the pipeline, parameter grid (param_grid), and cross-validation strategy (cv=kfold) to perform grid search.\n",
    "    * Fit the grid search object to your training data (X_train, y_train) to find the best model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 09:38:10.660990: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 09:38:11.994072: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-17 09:38:11.998588: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-17 09:38:14.076640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "def create_baseline():\n",
    "    # Code starts here\n",
    "    model = keras.Sequential([keras.layers.Dense(60,input_shape=(60,), activation = 'relu', kernel_initializer='normal'),\n",
    "                             keras.layers.Dense(40, activation = 'relu'),\n",
    "                             keras.layers.Dense(20, activation = 'relu'),\n",
    "                             keras.layers.Dense(10, activation = 'relu'),\n",
    "                             keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer='normal')])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train,y_train,epochs=10)\n",
    "    model.evaluate(X_test,y_test)\n",
    "    # Code ends here\n",
    "    \n",
    "    return model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1677/3987844067.py:7: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  ('keras', KerasClassifier(build_fn=create_baseline, verbose=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6890 - accuracy: 0.5843\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.7349\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.7831\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.7952\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7952\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.8133\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.8313\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.8614\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3797 - accuracy: 0.8675\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8571\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=10; total time=   2.1s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6912 - accuracy: 0.5723\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.8193\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.8675\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.8916\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.8976\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.9096\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.9096\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.9096\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.9277\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3861 - accuracy: 0.9277\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=10; total time=   1.7s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6935 - accuracy: 0.4759\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.6867\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.7169\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.7289\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.7349\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6536 - accuracy: 0.7410\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.7590\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5970 - accuracy: 0.8253\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.8373\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.4944 - accuracy: 0.8434\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=10; total time=   2.0s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6921 - accuracy: 0.5602\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.6687\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.7892\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.8373\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.8494\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.8494\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.8494\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.8494\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.8614\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8675\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6918 - accuracy: 0.5241\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.7530\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.7651\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.7952\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.7952\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.7892\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.8012\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.8313\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.8434\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.8434\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd362ee3f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.8333\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd362b42160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.5422\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.7711\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6866 - accuracy: 0.8072\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.8133\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.8193\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.8494\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.8373\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.8253\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.8313\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.8494\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd362b42940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.8333\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd362a93160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6921 - accuracy: 0.5964\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.8313\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.8373\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.8554\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.8554\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.8795\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.8976\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.9036\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.9036\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.9157\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6899 - accuracy: 0.6747\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.7169\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.7530\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.7711\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.7892\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.8193\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.8253\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.8434\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.8735\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5181\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.6506\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7229\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.7771\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.7892\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.8012\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.8614\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5467 - accuracy: 0.8795\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.8916\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.9157\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4915 - accuracy: 0.8810\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=10; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6936 - accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.7108\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.7952\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.8614\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.8614\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.8916\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.8916\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.8916\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5848 - accuracy: 0.8795\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.8735\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5413 - accuracy: 0.8571\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=10; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6929 - accuracy: 0.5542\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.7048\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.7470\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.7470\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.7470\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.7711\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.7771\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7831\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7952\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.8193\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=20; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6913 - accuracy: 0.5060\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5301\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.5422\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.5964\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.6627\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.7048\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.7410\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.7651\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5233 - accuracy: 0.7952\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.8494\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7143\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=20; total time=   2.2s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6919 - accuracy: 0.5723\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.7229\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.7952\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.8072\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.8193\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.8373\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.8434\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.8313\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.8313\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8614\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.8810\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=20; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6910 - accuracy: 0.5904\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.7530\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.7831\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.7892\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.8133\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.8373\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.8373\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.8614\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.8675\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6914 - accuracy: 0.5904\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.7711\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.8313\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.8614\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.8675\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.8855\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.8916\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.8976\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.9096\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.9096\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.6205\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.7771\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.7892\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.8133\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.8133\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.8313\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.8434\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.8735\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.9036\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6934 - accuracy: 0.4940\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.5181\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.5783\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.6145\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.6747\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.7169\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.7590\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7831\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5246 - accuracy: 0.8072\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8494\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5714 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=20; total time=   2.0s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6905 - accuracy: 0.5482\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.6867\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6681 - accuracy: 0.7289\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6515 - accuracy: 0.7470\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.7892\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5996 - accuracy: 0.8072\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.8313\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.8434\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8554\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3841 - accuracy: 0.8916\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4326 - accuracy: 0.8571\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6920 - accuracy: 0.5663\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.7711\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.8434\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.8675\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.8735\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.8795\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.8554\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.8735\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8855\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8855\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.8571\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=20; total time=   1.7s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6902 - accuracy: 0.4940\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6803 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6686 - accuracy: 0.5181\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6538 - accuracy: 0.5542\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.6265\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6085 - accuracy: 0.6747\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5805 - accuracy: 0.7289\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7530\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.8012\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8193\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.7381\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6918 - accuracy: 0.4880\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5361\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.5482\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.5482\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.6024\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.6506\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.6928\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7530\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5489 - accuracy: 0.8072\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8373\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7143\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=30; total time=   2.2s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6921 - accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.5904\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.6386\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.7169\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.7651\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.8193\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.8373\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5752 - accuracy: 0.8494\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.8554\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.8855\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5519 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=30; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6904 - accuracy: 0.6084\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.7590\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.7892\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.8193\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.8373\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.8434\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.8434\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.8434\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.8614\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8795\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.8571\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.5301\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.7289\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6774 - accuracy: 0.7470\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.7711\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.7651\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.7771\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.8253\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.8253\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.8554\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.8916\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5575 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5361\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.6988\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.7470\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.7651\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.7410\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.7410\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.7530\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.7530\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5827 - accuracy: 0.7590\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.7892\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5713 - accuracy: 0.7143\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.4699\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.6867\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.7590\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6745 - accuracy: 0.7831\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.8012\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.8253\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.8253\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5819 - accuracy: 0.8494\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.8554\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.8614\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.7143\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.6084\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.8012\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.8494\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.8434\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.8434\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6308 - accuracy: 0.8494\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.8434\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.8675\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8795\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8571\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=30; total time=   1.7s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6915 - accuracy: 0.6506\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.7711\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.7651\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.7711\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.7711\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.8012\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.8012\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5540 - accuracy: 0.8253\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.8313\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.8735\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5037 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=30; total time=   1.7s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6901 - accuracy: 0.6145\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.6506\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.7169\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.7410\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.7530\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.7952\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5808 - accuracy: 0.8133\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.8434\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.8735\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8855\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4575 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.6506\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.7169\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.7771\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.7831\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6417 - accuracy: 0.8373\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6144 - accuracy: 0.8434\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5753 - accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.8855\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.8571\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=16, keras__epochs=30; total time=   2.2s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6915 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.6024\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.6988\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6600 - accuracy: 0.7289\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6413 - accuracy: 0.7590\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6149 - accuracy: 0.8012\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.8133\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.8253\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.8434\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.8735\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5502 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6940 - accuracy: 0.4940\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.4940\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.4940\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.4940\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.5361\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.5783\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.6145\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.7108\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7651\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.8012\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5972 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.5181\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.5181\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.5181\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.5241\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6566\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6216 - accuracy: 0.7169\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5892 - accuracy: 0.7831\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.8193\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.8373\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4785 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.4880\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.5361\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.5602\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.6205\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6504 - accuracy: 0.6386\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.7169\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6018 - accuracy: 0.7229\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.7590\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7952\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.8675\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5861 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.5542\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.7349\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6856 - accuracy: 0.7892\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.7711\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.7771\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.8133\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.8193\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.8253\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.8253\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.8554\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4812 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6907 - accuracy: 0.5723\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.7590\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.7892\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.8072\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.8253\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.8554\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5382 - accuracy: 0.8855\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.9036\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.9096\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8571\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6894 - accuracy: 0.5241\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.7229\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.8133\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.8193\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.8193\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5740 - accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.8313\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.8494\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8855\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.9036\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=10; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.5241\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.7410\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.7651\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.8253\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6578 - accuracy: 0.8614\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.8554\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.8675\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.8916\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.9157\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.9217\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.7381\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 2s 3ms/step - loss: 0.6921 - accuracy: 0.5482\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.7470\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.8253\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.8675\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.8554\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.8554\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.8675\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.8735\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8916\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=10; total time=   2.3s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.5422\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.6386\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.7530\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.7831\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.8072\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.8253\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.8373\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.8313\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.8313\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8554\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6920 - accuracy: 0.6084\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.7410\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.8133\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.8494\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.8916\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6008 - accuracy: 0.8855\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.9036\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.9096\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.9277\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6919 - accuracy: 0.6205\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.7831\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.8313\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.8434\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.8735\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.8795\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6043 - accuracy: 0.8795\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5623 - accuracy: 0.8855\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.8916\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8976\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6928 - accuracy: 0.4759\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5904\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6827 - accuracy: 0.7048\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.7289\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.8133\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.8313\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.8434\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.8614\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.8855\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6913 - accuracy: 0.6687\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.7169\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.7169\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.7289\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.7590\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.7771\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6113 - accuracy: 0.7831\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7892\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.8253\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.8614\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6912 - accuracy: 0.6566\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.8012\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.8012\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.8072\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.8253\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.8614\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.8614\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.8795\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.9096\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.9458\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6938 - accuracy: 0.4940\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5241\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.5843\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.6506\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.7349\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.7590\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.7771\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.7831\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.8012\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.8373\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5890 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.6024\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6880 - accuracy: 0.7892\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.8313\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.8554\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.8795\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.9036\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.9096\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.9036\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.9157\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 2s 3ms/step - loss: 0.6918 - accuracy: 0.4940\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.4940\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.5241\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.5361\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.5602\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.6084\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.6867\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5405 - accuracy: 0.7590\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.8072\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.8373\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6237 - accuracy: 0.7381\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=20; total time=   2.3s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6931 - accuracy: 0.5542\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.6566\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6905 - accuracy: 0.7831\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.7771\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.8313\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.8494\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.8554\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.8494\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.8614\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.8675\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=20; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6924 - accuracy: 0.4880\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.7349\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.7831\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.7711\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.7831\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.8072\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.8253\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.8554\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.8795\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.7410\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7771\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.7711\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.7831\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.8072\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5904 - accuracy: 0.8313\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.8434\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.9096\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.8810\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6926 - accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.6928\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.7470\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.7952\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.8133\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.8554\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.8614\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.8494\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.8855\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4888 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.5663\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.6807\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.7590\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.7711\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.7952\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.7892\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.8072\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.8614\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.8735\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5462 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=30; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6899 - accuracy: 0.6265\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.7470\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.7651\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.7952\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.8072\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.8133\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.8253\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.8614\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8735\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.8571\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.5241\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.7169\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6763 - accuracy: 0.7349\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.7651\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6463 - accuracy: 0.7771\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.8012\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5896 - accuracy: 0.8193\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.8373\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.8494\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.8976\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5129 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.5060\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.5422\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5422\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.5542\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.5964\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.6747\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.6928\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7229\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.7590\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.8193\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7381\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 2s 3ms/step - loss: 0.6939 - accuracy: 0.4157\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.7470\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.8554\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.9096\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.8916\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.9036\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6343 - accuracy: 0.9217\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.9157\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.9157\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.9277\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5073 - accuracy: 0.8571\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=30; total time=   2.4s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6929 - accuracy: 0.5361\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.6807\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6799 - accuracy: 0.7349\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.7831\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.7831\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.8373\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.8614\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.8735\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4958 - accuracy: 0.8795\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8855\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=30; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6904 - accuracy: 0.5542\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.6265\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6748 - accuracy: 0.6687\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.6867\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.6928\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.7169\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.7530\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.8072\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.8133\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.8554\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6914 - accuracy: 0.6084\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.7169\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.7048\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.7410\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.7651\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.8012\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.8494\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.8373\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.8675\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5589 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=32, keras__epochs=30; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6923 - accuracy: 0.4880\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6874 - accuracy: 0.6627\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.6988\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.7048\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.7229\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.7651\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.7952\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.8072\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.8193\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.8494\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5225 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6942 - accuracy: 0.4699\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.6024\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.6747\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.6747\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6777 - accuracy: 0.6807\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.7169\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.7410\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.7651\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.7831\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7892\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7381\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6910 - accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5241\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.5964\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.6325\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.6747\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.7349\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7530\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7771\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.8072\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.8373\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7381\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6912 - accuracy: 0.6205\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.7470\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.7952\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.8133\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.8253\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.8494\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.8855\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8976\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6904 - accuracy: 0.6265\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.7651\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.8133\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6631 - accuracy: 0.8373\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.8373\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.8434\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.8554\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5326 - accuracy: 0.8795\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.9036\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.9036\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6908 - accuracy: 0.6325\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.7831\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6759 - accuracy: 0.8253\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.8253\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.8434\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.8614\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.8795\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.8916\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8855\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8916\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 2s 3ms/step - loss: 0.6928 - accuracy: 0.4880\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.6386\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6808 - accuracy: 0.6988\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7590\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.7711\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.7952\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.8072\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5789 - accuracy: 0.8313\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.8916\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=10; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6895 - accuracy: 0.5783\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.6446\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6704 - accuracy: 0.7108\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.7892\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.8012\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.7952\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.8193\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.8434\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.8554\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8855\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.5482\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.7831\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.8373\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.8494\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.8795\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.8795\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.8795\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.8976\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.8916\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8916\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.8571\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=10; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6903 - accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.6687\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.7349\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.7651\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7651\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6049 - accuracy: 0.7892\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.8072\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.8253\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8554\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8855\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=10; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.5422\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.5843\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5542\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.5964\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6928\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.7470\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.7831\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.7952\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.8072\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.8193\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6903 - accuracy: 0.5843\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7470\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.7831\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.8012\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.8313\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.8434\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.8675\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.8735\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8735\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8976\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6905 - accuracy: 0.5723\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.6867\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.6627\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.6627\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.6627\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6216 - accuracy: 0.6988\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.7651\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7831\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.8373\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8614\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6053 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.5060\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.8012\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.8434\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.8675\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.8795\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.8735\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.8916\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.8795\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.8675\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=20; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6909 - accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6843 - accuracy: 0.5060\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6767 - accuracy: 0.5120\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.5241\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.5783\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6084\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.6687\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5729 - accuracy: 0.7048\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7289\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7831\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6346 - accuracy: 0.6905\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=20; total time=   1.7s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6915 - accuracy: 0.5663\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.7289\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.7470\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.7470\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.7711\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.7771\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7952\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7952\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.8494\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.8916\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=20; total time=   2.2s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6930 - accuracy: 0.4578\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.6265\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.6687\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6799 - accuracy: 0.6988\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.7349\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.7530\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6314 - accuracy: 0.7831\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5992 - accuracy: 0.7952\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.8253\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8554\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=20; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6907 - accuracy: 0.5723\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.7410\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.7590\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6628 - accuracy: 0.7711\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.7771\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.7892\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.8072\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.8193\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.8313\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8855\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=20; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6903 - accuracy: 0.5783\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.6928\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.7590\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.7349\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6457 - accuracy: 0.7289\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6209 - accuracy: 0.7349\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.7349\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7711\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7771\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7952\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5357 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6919 - accuracy: 0.5060\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.7289\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.8012\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.8313\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.8313\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.8373\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.8494\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.8735\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.8855\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8976\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7857\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=20; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6897 - accuracy: 0.6747\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.8012\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.8133\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.8193\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.8373\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.8434\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.8494\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8795\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.8976\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=30; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6916 - accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.6325\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.7229\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.7108\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.7229\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7229\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5960 - accuracy: 0.7651\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.7952\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.8012\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.8072\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6927 - accuracy: 0.5602\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.7651\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.8072\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.8494\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.8675\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.8735\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6156 - accuracy: 0.8735\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5741 - accuracy: 0.8795\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.8855\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8976\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6933 - accuracy: 0.5060\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.5241\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6888 - accuracy: 0.5120\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.5542\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6774 - accuracy: 0.5602\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.5843\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.6145\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6747\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.6928\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7349\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6260 - accuracy: 0.6667\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6917 - accuracy: 0.5602\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.7048\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.8012\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.8133\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.8313\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.8434\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.8675\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.8735\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.8795\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5076 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 2s 3ms/step - loss: 0.6936 - accuracy: 0.4759\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6902 - accuracy: 0.7169\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.7831\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.7952\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.8133\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.8373\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.8494\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.8916\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=30; total time=   2.5s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6908 - accuracy: 0.5361\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.6145\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6801 - accuracy: 0.6988\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.8193\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.8614\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.8675\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.8795\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.8795\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.8976\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.9096\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.8095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=30; total time=   1.9s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 0.6916 - accuracy: 0.5904\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.6866 - accuracy: 0.7530\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6805 - accuracy: 0.7831\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.7530\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.7530\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6429 - accuracy: 0.8012\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.8373\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.8554\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.8675\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.8855\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.8333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=30; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6918 - accuracy: 0.4940\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.4940\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.5060\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.5422\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.5783\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6205\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.6687\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5658 - accuracy: 0.7349\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7651\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.8193\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6086 - accuracy: 0.7619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=30; total time=   1.8s\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 0.6925 - accuracy: 0.4940\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5602\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6776 - accuracy: 0.6024\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.5301\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.5301\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.5482\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.5602\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.6867\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7711\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8313\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6331 - accuracy: 0.7143\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "[CV] END .............keras__batch_size=64, keras__epochs=30; total time=   1.8s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 90 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n90 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/labuser/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/labuser/.local/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/labuser/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/home/labuser/.local/lib/python3.8/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/home/labuser/.local/lib/python3.8/site-packages/keras/wrappers/scikit_learn.py\", line 167, in fit\n    losses.is_categorical_crossentropy(self.model.loss)\nAttributeError: 'numpy.ndarray' object has no attribute 'loss'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Perform Grid Search\u001b[39;00m\n\u001b[1;32m     20\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mpipeline, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39mkfold, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Print best parameters and best score\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_result\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 90 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n90 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/labuser/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/labuser/.local/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/home/labuser/.local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"/home/labuser/.local/lib/python3.8/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n    return super().fit(x, y, **kwargs)\n  File \"/home/labuser/.local/lib/python3.8/site-packages/keras/wrappers/scikit_learn.py\", line 167, in fit\n    losses.is_categorical_crossentropy(self.model.loss)\nAttributeError: 'numpy.ndarray' object has no attribute 'loss'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Create a pipeline with KerasClassifier for Grid Search\n",
    "pipeline = Pipeline([\n",
    "    ('keras', KerasClassifier(build_fn=create_baseline, verbose=0))\n",
    "])\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'keras__batch_size': [16, 32, 64],\n",
    "    'keras__epochs': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=kfold, verbose=2)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and best score\n",
    "print(f\"Best parameters: {grid_result.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_result.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.create_baseline()>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize result\n",
    "create_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LljG34t2erm"
   },
   "source": [
    "The results indicate the performance of the baseline model and its variations with different hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Utilizes Keras and scikit-learn to create and train a neural network model with the specified parameters.\n",
    "* Train the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOmzw30_2g2Q",
    "outputId": "715d6800-a42e-4694-eff0-65d4a4316e03"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kr-4HXymKMNZ"
   },
   "source": [
    "### Task 3: Evaluate the performance of the model using the right evaluation metrics. (weightage - 25 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlNMhWlAKQxv"
   },
   "source": [
    "#### T3.1: Bring the â€˜NN-Modelâ€™ from a GitHub using git commands and evaluate the model.(ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSzuC4O0MARl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFD6ePsPMBjS"
   },
   "source": [
    "#### T3.2:  Evaluate the NN model with evaluation metrics accuracy, precision, recall, f1 score and roc auc score using sklearn library.(weightage -12 marks) (AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "* Create a method called `ROC_AUC` to calculate the ROC-AUC score for a given model's predictions on test data.\n",
    "* Accept three parameters:\n",
    "    model: The trained model for which you want to calculate ROC-AUC.\n",
    "    X_test: The feature matrix of the test data.\n",
    "    y_test: The true labels of the test data.\n",
    "* Calculate ROC-AUC Score:\n",
    "* Use the `predict_proba` method of the model to get the predicted probabilities of the positive class (class 1) for the test data. Ensure to select the probabilities of the positive class.\n",
    "* Set `verbose=0` to suppress output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4DZ3_dUozjay"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3571 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35709208250045776, 0.8333333134651184]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = keras.Sequential([keras.layers.Dense(60,input_shape=(60,), activation = 'relu'),\n",
    "                             keras.layers.Dense(40, activation = 'relu'),\n",
    "                             keras.layers.Dense(20, activation = 'relu'),\n",
    "                             keras.layers.Dense(10, activation = 'relu'),\n",
    "                             keras.layers.Dense(1, activation = 'sigmoid')])\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(X_train,y_train,epochs=12, verbose=0)\n",
    "model3.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrJcn-NbsJYf",
    "outputId": "9ac27dd8-49b9-45cf-a4a7-1231709c0b8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "y_predict = model3.predict(X_test, verbose=0)\n",
    "ROC_scores = roc_auc_score(y_test,y_predict)\n",
    "print(ROC_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "* Create a method called `evaluate_classification` to evaluate a classification model's performance on test data.\n",
    "* Accept three parameters:\n",
    "    model: The trained classification model to evaluate.\n",
    "    X_test: The feature matrix of the test data.\n",
    "    y_true: The true labels of the test data.\n",
    "* Calculate Evaluation Metrics\n",
    "* Use the predict method of the model to get the predicted labels for the test data.\n",
    "* Calculate evaluation metrics such as accuracy, precision, recall, and F1 score using functions like accuracy_score, precision_score, recall_score, and f1_score from sklearn.metrics in the same order.\n",
    "* Set `verbose=0` to suppress output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "vd5Is5NBrXMC"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def evaluate_classification(model, X_test, y_true):\n",
    "    # Predict the labels for the test data\n",
    "    y_predict_prob = model.predict(X_test, verbose=0)\n",
    "    y_predict = (y_predict_prob > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_predict)\n",
    "    precision = precision_score(y_true, y_predict, average='weighted')\n",
    "    recall = recall_score(y_true, y_predict, average='weighted')\n",
    "    f1 = f1_score(y_true, y_predict, average='weighted')\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_predict))\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EkLFGzo5rgzK",
    "outputId": "60d3fc07-3b99-48b5-ab06-8a6d9b8072d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87        27\n",
      "           1       0.75      0.80      0.77        15\n",
      "\n",
      "    accuracy                           0.83        42\n",
      "   macro avg       0.82      0.83      0.82        42\n",
      "weighted avg       0.84      0.83      0.83        42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8333333333333334, 0.8365384615384616, 0.8333333333333334, 0.834449178332319)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification(model3,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFNudo-Zy_dp"
   },
   "source": [
    "After hyperparameter tuning,it has been observed that the parameters 'mlp__batch_size' of 5, 'mlp__epochs'of 150 has given a good accuracy score. The model is then tested on the test dataset and is observed that it works well with a precision score of 0.94,recall of 0.81 and a f1score of 0.871. This classification model can be used to distinguish the rocks from metal cylinders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ml5GGQo7N773"
   },
   "source": [
    "#### T3.3 Using Lime/SHAP libraries, explain the prediction of your  model and give inferences. (weightage- 5marks) (ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7878uXfkOGz9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nh9cb6ZzOH_b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKr2YB6hOI5u"
   },
   "source": [
    "#### T3.4 Implement the unit test case and deploy a model using Flask / Streamlit. (weightage-15 marks) (ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "\n",
    "* Define a Sequential model keras_model using `Sequential()` from Keras.\n",
    "* Add layers to `keras_model` to match the architecture of your trained model:\n",
    "* Add a Dense layer with 60 units, input dimension of 60, 'normal' kernel initializer, and 'relu' activation.\n",
    "* Add another Dense layer with 1 unit for binary classification, 'normal' kernel initializer, and 'sigmoid' activation.\n",
    "* Load Trained Model Weights.\n",
    "* Use keras_model.set_weights(model.model.get_weights()) to load the weights from the trained model model into your keras_model. This assumes that model is an instance of KerasClassifier or KerasRegressor from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rVetAcYOqK4",
    "outputId": "c929e078-4227-4703-80ad-790151f44c4f"
   },
   "outputs": [],
   "source": [
    "# Save the Keras model to an HDF5 file\n",
    "from keras.models import Sequential, save_model\n",
    "\n",
    "# Recreate the Keras model\n",
    "\n",
    "\n",
    "# Load the weights from the best KerasClassifier model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Keras model to an HDF5 file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Submission guidelines: \n",
    "1.\tDownload the Jupyter notebook in the format of html. \n",
    "2.\tUpload it in the lumen (UNext LMS)\n",
    "3.\tTake a screenshot of T3.4 (Deployment) and upload it in the lumen (UNext LMS)\n",
    "4.\tSummarized PPT/ PDF prepared in Task 4 to be uploaded in the lumen (UNext LMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------- **ASSESSMENT ENDS HERE** ---------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
